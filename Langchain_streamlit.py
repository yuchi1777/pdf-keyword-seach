import os
import streamlit as st
import tempfile
import fitz  # PyMuPDF
import pandas as pd

# Streamlit UI
st.title("ğŸ“„ PDF é—œéµå­—æœå°‹å·¥å…·")

# ä¸Šå‚³ PDF æª”æ¡ˆ
uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ PDF æª”æ¡ˆ", type=["pdf"], accept_multiple_files=True)

# ä¸Šå‚³é—œéµå­—æª”æ¡ˆï¼ˆTXT æˆ– Excelï¼‰
keywords_file = st.file_uploader("è«‹ä¸Šå‚³é—œéµå­—æª”æ¡ˆ (TXT æˆ– Excel)", type=["txt", "xlsx"])

def load_keywords(file):
    """è®€å–é—œéµå­—ï¼Œå¯æ”¯æ´ TXT æˆ– Excel"""
    if file is not None:
        if file.name.endswith(".txt"):
            keywords = [line.strip() for line in file.getvalue().decode("utf-8").splitlines() if line.strip()]
        elif file.name.endswith(".xlsx"):
            df = pd.read_excel(file)
            keywords = set()
            for col in df.columns:
                keywords.update(df[col].dropna().astype(str).tolist())
            keywords = list(keywords)
        else:
            st.error("âŒ ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ï¼Œè«‹ä½¿ç”¨ .txt æˆ– .xlsx")
            return []
        return keywords
    return []

def extract_text_from_pdf(uploaded_files):
    """ä½¿ç”¨ PyMuPDF è§£æ PDF ä¸¦æå–æ–‡å­—"""
    documents = []
    
    for uploaded_file in uploaded_files:
        try:
            # é¡¯ç¤ºè™•ç†ä¸­ç‹€æ…‹
            with st.spinner(f"æ­£åœ¨è™•ç† {uploaded_file.name}..."):
                # å‰µå»ºè‡¨æ™‚æª”æ¡ˆå­˜å„² PDF
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                    tmp_file.write(uploaded_file.read())
                    tmp_file_path = tmp_file.name
                
                # è®€å– PDF å…§å®¹
                doc = fitz.open(tmp_file_path)
                for page_num, page in enumerate(doc):
                    raw_text = page.get_text("text") or ""
                    # ä¿®æ­£æ–·è¡Œï¼šcarboxy-\nmethylcellulose â†’ carboxymethylcellulose
                    text = raw_text.replace("-\n", "").replace("\n", " ")
                    documents.append({
                        "file": uploaded_file.name,
                        "page": page_num + 1,
                        "content": text
                    })
                
                doc.close()
                os.remove(tmp_file_path)  # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ
        
        except Exception as e:
            st.error(f"âŒ ç„¡æ³•è¼‰å…¥ {uploaded_file.name}: {e}")
    
    return documents

def search_keywords_exact(documents, keywords):
    """å®Œå…¨æ¯”å°é—œéµå­—ï¼ˆå¤§å°å¯«ç„¡é—œï¼‰"""
    results = []
    for doc in documents:
        file_name = doc["file"]
        page_number = doc["page"]
        content = doc["content"]
        
        for keyword in keywords:
            if keyword.lower() in content.lower():
                results.append({
                    "file": file_name,
                    "keyword": keyword,
                    "page": page_number
                })
    
    return results

def display_results(results):
    """é¡¯ç¤ºæœå°‹çµæœ"""
    if results:
        st.success("âœ… æŸ¥è©¢å®Œæˆï¼")
        for result in results:
            st.write(f"ğŸ“„ æª”æ¡ˆ: {result['file']} | ğŸ” é—œéµå­—: {result['keyword']} | ğŸ“„ é æ•¸: {result['page']}")
    else:
        st.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•é—œéµå­—ï¼")

# åŸ·è¡Œä¸»ç¨‹å¼
if uploaded_files and keywords_file:
    st.write("ğŸš€ æª”æ¡ˆä¸Šå‚³å®Œæˆï¼Œé–‹å§‹è™•ç†ä¸­...")
    
    keywords = load_keywords(keywords_file)
    if not keywords:
        st.warning("âš ï¸ æœªèƒ½è®€å–ä»»ä½•é—œéµå­—ï¼Œè«‹æª¢æŸ¥ä¸Šå‚³çš„æª”æ¡ˆæ ¼å¼ã€‚")
    else:
        documents = extract_text_from_pdf(uploaded_files)
        if not documents:
            st.warning("æœªèƒ½è§£æä»»ä½• PDF å…§å®¹ï¼Œè«‹ç¢ºèªä¸Šå‚³çš„æª”æ¡ˆæ ¼å¼ã€‚")
        else:
            st.write("ğŸ” æ­£åœ¨æœå°‹é—œéµå­—...")
            search_results = search_keywords_exact(documents, keywords)
            display_results(search_results)
