import os
import pandas as pd
import re
import streamlit as st
import tempfile
from collections import defaultdict
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

def load_keywords(file):
    """è®€å–é—œéµå­—ï¼Œå¯æ”¯æ´ TXT æˆ– Excel"""
    if file is not None:
        if file.name.endswith(".txt"):
            keywords = [line.strip() for line in file.getvalue().decode("utf-8").splitlines() if line.strip()]
        elif file.name.endswith(".xlsx"):
            df = pd.read_excel(file)
            keywords = set()
            for col in df.columns:
                keywords.update(df[col].dropna().astype(str).tolist())
            keywords = list(keywords)
        else:
            st.error("âŒ ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ï¼Œè«‹ä½¿ç”¨ .txt æˆ– .xlsx")
            return []
        return keywords
    return []

def load_and_split_documents(uploaded_files):
    """è™•ç†ä¸Šå‚³çš„ PDF æ–‡ä»¶"""
    all_documents = []
    
    for uploaded_file in uploaded_files:
        try:
            # å‰µå»ºè‡¨æ™‚æª”æ¡ˆå­˜å„² PDF
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_file_path = tmp_file.name
            
            # ä½¿ç”¨ PyPDFLoader è®€å–è‡¨æ™‚ PDF
            loader = PyPDFLoader(tmp_file_path)
            documents = loader.load()
            
            # è¨˜éŒ„æ–‡ä»¶åç¨±
            for doc in documents:
                doc.metadata['source'] = uploaded_file.name
            
            # åˆ‡å‰²æ–‡æœ¬
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            all_documents.extend(text_splitter.split_documents(documents))
            
            # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ
            os.remove(tmp_file_path)
        except Exception as e:
            st.error(f"âŒ ç„¡æ³•è¼‰å…¥ {uploaded_file.name}: {e}")
    return all_documents

def search_keywords_exact(documents, keywords):
    """ç¢ºä¿é—œéµå­—åŒ¹é…å®Œå…¨ä¸€è‡´ï¼ˆå¤§å°å¯«ç„¡é—œï¼Œä½†å…§å®¹å®Œå…¨åŒ¹é…ï¼‰"""
    results = []
    for doc in documents:
        page_number = doc.metadata.get('page', 'Unknown')
        source_file = doc.metadata.get('source', 'Unknown File')
        content = doc.page_content
        
        for keyword in keywords:
            if re.search(rf'\b{re.escape(keyword)}\b', content, re.IGNORECASE):
                snippet = doc.page_content[:200]
                results.append({'file': source_file, 'keyword': keyword, 'page': page_number, 'content': snippet})
    return results

def display_results(results):
    """é¡¯ç¤ºæœå°‹çµæœ"""
    if results:
        for result in results:
            st.subheader(f"ğŸ“„ ä¾†æºæª”æ¡ˆ: {result['file']}")
            st.write(f"ğŸ” é—œéµå­—: {result['keyword']}")
            st.write(f"ğŸ“„ é æ•¸: {result['page']}")
            st.text(result['content'])
            st.markdown("---")

def save_results_to_excel(results):
    """å°‡æœå°‹çµæœå­˜ç‚º Excel"""
    df = pd.DataFrame(results, columns=["ä¾†æºæª”æ¡ˆ", "é—œéµå­—", "é æ•¸", "å…§å®¹"])
    df.to_excel("keyword_search_results.xlsx", index=False)
    st.success("ğŸ“„ æœå°‹çµæœå·²å„²å­˜ç‚º keyword_search_results.xlsx")

# Streamlit UI
st.title("ğŸ“„ PDF é—œéµå­—æœå°‹å·¥å…·")

uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ PDF æª”æ¡ˆ", type=["pdf"], accept_multiple_files=True)
keywords_file = st.file_uploader("è«‹ä¸Šå‚³é—œéµå­—æª”æ¡ˆ (TXT æˆ– Excel)", type=["txt", "xlsx"])

if uploaded_files and keywords_file:
    keywords = load_keywords(keywords_file)
    if not keywords:
        st.warning("âš ï¸ æœªèƒ½è®€å–ä»»ä½•é—œéµå­—ï¼Œè«‹æª¢æŸ¥ä¸Šå‚³çš„æª”æ¡ˆæ ¼å¼ã€‚")
    else:
        documents = load_and_split_documents(uploaded_files)
        if not documents:
            st.warning("æœªèƒ½è§£æä»»ä½• PDF å…§å®¹ï¼Œè«‹ç¢ºèªä¸Šå‚³çš„æª”æ¡ˆæ ¼å¼ã€‚")
        else:
            st.write("ğŸ” æ­£åœ¨æœå°‹é—œéµå­—...")
            search_results = search_keywords_exact(documents, keywords)
            display_results(search_results)
            save_results_to_excel(search_results)
